# AI-Based Project Ideas: Image-to-Text & Image-to-Image
This repository is for providing some ideas to develop.

<details>
  <summary>1️⃣ Image Captioning (General)</summary>
  
  ### 🧠 Foundational Models
  - **GIT (Generative Image-to-Text Transformer)** – Uses a vision encoder and text decoder for image captioning.
  - **BLIP (Bootstrapped Language-Image Pretraining)** – Enhances vision-language pretraining for better text generation.
  - **CoCa (Contrastive Captioners)** – Combines contrastive learning with an encoder-decoder framework.

  ### 🏆 Benchmark Datasets
  - **MS COCO Captioning Dataset** (~330K images, five captions per image) – [Link](https://cocodataset.org/#home)
  - **Flickr30K** (~30K images, five captions per image) – [Link](https://shannon.cs.illinois.edu/DenotationGraph/)

  ### 📖 Reading Materials
  - [GIT Paper (arXiv)](https://arxiv.org/abs/2205.14100)
  - [CoCa Paper (arXiv)](https://arxiv.org/abs/2205.01917)
</details>

<details>
  <summary>2️⃣ Medical Image Captioning (CT Scan Report Generation)</summary>
  
  ### 🧠 Foundational Models
  - **CT2Rep** – Automated **radiology report generation** for 3D medical imaging.
  - **Multi-modal Transformers (e.g., MedViLL, BioViL-T)** – Optimized for **vision-language tasks** in the medical domain.

  ### 🏆 Benchmark Datasets
  - **MIMIC-CXR** (Chest X-ray dataset with reports) – [Link](https://physionet.org/content/mimic-cxr/2.0.0/)
  - **IU X-ray Dataset** (Chest X-rays with structured radiology reports) – [Link](https://openi.nlm.nih.gov/)

  ### 📖 Reading Materials
  - [CT2Rep: Automated Radiology Report Generation](https://arxiv.org/html/2403.06801v1)
  - [Multi-modal Transformer for Medical Image Captioning](https://www.nature.com/articles/s41598-024-69981-5)
</details>

<details>
  <summary>3️⃣ AI-Based Trending Hashtag Generator for Instagram</summary>
  
  ### 🧠 Foundational Models
  - **CLIP (Contrastive Language-Image Pertaining)** – Matches images with text descriptions (great for hashtag relevance).
  - **BLIP (Bootstrapped Language-Image Pertaining)** – Can generate **context-aware captions and hashtags**.

  ### 🏆 Benchmark Datasets
  - **Instagram Hashtag Dataset** – [Example Dataset on Kaggle](https://www.kaggle.com/datasets/nikhilb25/instagram-data)
  - **Hateful Memes (Facebook Research)** – Useful for **image-text** associations – [Link](https://www.drivendata.org/competitions/64/hateful-memes/)

  ### 📖 Reading Materials
  - [Using CLIP for Hashtag Prediction](https://arxiv.org/pdf/2103.00020.pdf)
  - [AI-Powered Hashtag Optimization](https://www.semanticscholar.org/paper/Hashtag-Prediction-for-Social-Media-Posts-Using-Liu-Hua/9735e1f25dbb8d7ec1c7b7714e1f256d038d46d6)
</details>

<details>
  <summary>4️⃣ Video/Text-to-Animation Generation (Creative 🎥✨) - Milad is going to update this section </summary>
  
  ### 🧠 Foundational Models
  
  ### 🏆 Benchmark Datasets
  
  ### 📖 Reading Materials
</details>




